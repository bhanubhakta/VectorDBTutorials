{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhanubhakta/VectorDBTutorials/blob/main/VectorEmbedding/TextEmbedding/GloVe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H60LJ3c7pYnw",
        "outputId": "b8d31881-eaed-4f9f-f7fb-6925adcb08a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to 'king': [('prince', 0.8236179351806641), ('queen', 0.7839043140411377), ('ii', 0.7746230363845825), ('emperor', 0.7736247777938843), ('son', 0.766719400882721), ('uncle', 0.7627150416374207), ('kingdom', 0.7542160749435425), ('throne', 0.7539913654327393), ('brother', 0.7492411136627197), ('ruler', 0.7434253692626953)]\n",
            "'man' is to 'women' as 'king' is to queen\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Step 1: Load a pre-trained GloVe model\n",
        "# Here, we are using a small pre-trained GloVe model available in Gensim's data repository for simplicity.\n",
        "# The 'glove-wiki-gigaword-50' model uses 50-dimensional vectors and is trained on Wikipedia data.\n",
        "glove_model = api.load(\"glove-wiki-gigaword-50\")\n",
        "\n",
        "# Step 2: Explore the model\n",
        "# Let's find out which words are most similar to 'king' using the GloVe model\n",
        "similar_to_king = glove_model.most_similar('king')\n",
        "print(\"Words similar to 'king':\", similar_to_king)\n",
        "\n",
        "# Optional: Train your own GloVe model\n",
        "# Note: Training your own GloVe model from scratch requires more setup and is generally more involved.\n",
        "# We recommend using pre-trained models for beginner examples.\n",
        "\n",
        "# Solve the analogy\n",
        "result = glove_model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
        "print(f\"'man' is to 'women' as 'king' is to {result[0][0]}\")\n",
        "\n"
      ]
    }
  ]
}